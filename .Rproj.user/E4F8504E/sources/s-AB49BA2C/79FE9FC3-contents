
remove(list = ls())


setwd("/home/marlon/mainfolder/marlon/USFQ/DataMining/5_Clasificacion/P5")


#Escoger training y test data sets
dataset = readRDS("SPECTF_FINAL.rds")

dataset$OVERALL_DIAGNOSIS = as.factor(dataset$OVERALL_DIAGNOSIS)

summary(dataset)

(N = nrow(dataset))

target = round(N * 0.75)

gp = runif(N)

train_data = dataset[gp < 0.75,]
test_data = dataset[gp >= 0.75,]

#Data normalizada Min-Max
train_data_n = train_data
for(i in 2:ncol(train_data_n)){
    train_data_n[i] =  (train_data_n[i] - min(train_data_n[i]))/ (max(train_data_n[i]) - min(train_data_n[i])) * (1-0) + 0
}

test_data_n = test_data

for(i in 2:ncol(train_data_n)){
    test_data_n[i] =  (test_data_n[i] - min(test_data_n[i]))/ (max(test_data_n[i]) - min(test_data_n[i])) * (1-0) + 0
}


#Naive Bayes

library(naivebayes)

train_data_n$OVERALL_DIAGNOSIS = as.factor(train_data_n$OVERALL_DIAGNOSIS)

model = naive_bayes(OVERALL_DIAGNOSIS ~ ., data = train_data_n)

pred_data = predict(model, newdata = test_data_n[-1])

actual_data = test_data_n$OVERALL_DIAGNOSIS

table(pred_data, actual_data)

mean(pred_data == actual_data)

#KNN

library(class)

classes = train_data_n$OVERALL_DIAGNOSIS

pred_knn = knn(train = train_data_n[-1], test =test_data_n[-1][13,], cl = classes, k = 1) #Por default usa la distancia euclidiana

actual_pred = test_data_n$OVERALL_DIAGNOSIS

table(pred_knn, actual_pred)

mean(pred_knn == actual_pred)


# #Knn con distancia manhatann
# library(dplyr)
# train_test = train_data_n
# sample = test_data_n
# list = c()
# #for(ob in 1:nrow(sample)){
#     
#     #sa = sample[-1][ob,]
#     sa = sample[-1][12,]
#     print(sa)
#     column_names = names(sa)
#     
#     train_test$dist_mht = 0
#     k = 1
#     for(row in 1:nrow(sa)){
#         for(col in column_names){
#             train_test = train_test %>%
#                 mutate(dist_mht = dist_mht + (train_test[col] - as.numeric(sa[row, col]))^2)
#                 #mutate(dist_mht = dist_mht + abs(train_test[col] - as.numeric(sa[row, col])))
#         }
#         train_test = train_test %>%
#             mutate(dist_mht = sqrt(dist_mht))
#     }
#     
#     train_test = train_test %>%
#         arrange(dist_mht) %>%
#         top_n(dist_mht,n = -k)
#     
#     chose = train_test%>%
#         group_by(OVERALL_DIAGNOSIS) %>%
#         summarise(n = n()) %>%
#         top_n(n = 1, n) 
#     
#     #%>%
#     #     select(OVERALL_DIAGNOSIS)
# 
#     list = c(list, as.numeric(chose[1,1]) - 1)
#     
# #}



#TODO: Hay que implementar el knn para las dos distancias
#TODO: Hay que hacer el cross-validation para ver el mejor numero de K



